{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.cm as mpl_color_map\n",
    "from matplotlib.colors import LogNorm\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from CNN_Networks import OU200_CNN, VIS_CNN, JYH_CNN, OU66_CNN\n",
    "from CNN_Layer_VIS import CNNLayerVisualization\n",
    "from Generate_Class_Examples import ClassSpecificImageGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load States\n",
    "A dictionary containing all the weights for the CNNs used in the accompanning paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadStates = {'J': 'OU_J_Weights.pt',\n",
    "              'Y': 'OU_Y_Weights.pt',\n",
    "              'H': 'OU_H_Weights.pt',\n",
    "              'JYH': 'OU_JYH_Weights.pt',\n",
    "              'VIS': 'OU_VIS_Weights.pt',\n",
    "              'OU-66': 'OU_66_Weights.pt',\n",
    "              'OU-200': 'OU_200_Weights.pt'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise image maker\n",
    "We create an image of the same dimensions as the inputs to our CNN containing random uniform noise. We save this random noise image to allow us to use the same input image for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "onebandnoise = np.random.random((66,66))\n",
    "inputnoise = np.zeros((1,4,200,200))\n",
    "for i in range(4):\n",
    "    inputnoise[0,i,:,:] = resize(onebandnoise, (200,200))\n",
    "np.save('input_noise_OU200', inputnoise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Class Generated Images\n",
    "We first define a set of variables for this particluar run k (which is an identifying number for this run), lr (learning rate), range_Images (how many interations this process runs for), and rand_loc (location of the intial input image). \n",
    "\n",
    "The CNN is selected and loaded with the trained weights. The random image is loaded. The file locations for the output of this notebook are specificied depending on the target class. These input variables are given to the ClassSpecificImageGeneration() method and the noise image is updated to activate the target class. This function saves the numpy file of the image and a single band image every 10 interations. This process is carried out for both target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Loss 0.25 Acc: [0.37785983 0.62214017]\n",
      "Iteration: 2 Loss 0.17 Acc: [0.38496557 0.61503446]\n",
      "Iteration: 3 Loss -0.34 Acc: [0.6064154 0.3935846]\n",
      "Iteration: 4 Loss -0.50 Acc: [0.68301684 0.3169831 ]\n",
      "Iteration: 5 Loss -0.64 Acc: [0.7460161  0.25398383]\n",
      "Iteration: 6 Loss -0.67 Acc: [0.7649195 0.2350805]\n",
      "Iteration: 7 Loss -0.76 Acc: [0.7913174  0.20868258]\n",
      "Iteration: 8 Loss -0.91 Acc: [0.82867074 0.17132926]\n",
      "Iteration: 9 Loss -0.96 Acc: [0.8441642  0.15583578]\n",
      "Iteration: 10 Loss -1.05 Acc: [0.857437   0.14256305]\n",
      "Iteration: 11 Loss -1.02 Acc: [0.8723683  0.12763171]\n",
      "Iteration: 12 Loss -1.33 Acc: [0.91540956 0.08459049]\n",
      "Iteration: 13 Loss -1.30 Acc: [0.91500586 0.08499417]\n",
      "Iteration: 14 Loss -1.40 Acc: [0.9294658  0.07053424]\n",
      "Iteration: 15 Loss -1.46 Acc: [0.9378548 0.0621452]\n",
      "Iteration: 16 Loss -1.60 Acc: [0.9521125  0.04788755]\n",
      "Iteration: 17 Loss -1.60 Acc: [0.946157   0.05384297]\n",
      "Iteration: 18 Loss -1.61 Acc: [0.9556216  0.04437842]\n",
      "Iteration: 19 Loss -1.80 Acc: [0.96558315 0.03441681]\n",
      "Iteration: 20 Loss -1.91 Acc: [0.9730291  0.02697095]\n",
      "Iteration: 21 Loss -1.95 Acc: [0.9719339  0.02806611]\n",
      "Iteration: 22 Loss -1.88 Acc: [0.970501   0.02949899]\n",
      "Iteration: 23 Loss -1.82 Acc: [0.96084255 0.0391574 ]\n",
      "Iteration: 24 Loss -2.03 Acc: [0.9782693  0.02173075]\n",
      "Iteration: 25 Loss -2.08 Acc: [0.9751813  0.02481873]\n",
      "Iteration: 26 Loss -2.02 Acc: [0.9778055  0.02219454]\n",
      "Iteration: 27 Loss -2.04 Acc: [0.974918   0.02508197]\n",
      "Iteration: 28 Loss -2.21 Acc: [0.98434967 0.01565032]\n",
      "Iteration: 29 Loss -2.30 Acc: [0.9851983  0.01480169]\n",
      "Iteration: 30 Loss -2.34 Acc: [0.98639005 0.01360992]\n",
      "Iteration: 31 Loss -2.41 Acc: [0.98813266 0.01186734]\n",
      "Iteration: 32 Loss -2.46 Acc: [0.9894051  0.01059482]\n",
      "Iteration: 33 Loss -2.57 Acc: [0.9911675  0.00883251]\n",
      "Iteration: 34 Loss -2.60 Acc: [0.9918698  0.00813014]\n",
      "Iteration: 35 Loss -2.67 Acc: [0.99243104 0.00756892]\n",
      "Iteration: 36 Loss -2.62 Acc: [0.99248576 0.00751416]\n",
      "Iteration: 37 Loss -2.79 Acc: [0.9940698  0.00593023]\n",
      "Iteration: 38 Loss -2.86 Acc: [0.9950193 0.0049807]\n",
      "Iteration: 39 Loss -2.85 Acc: [0.9945703  0.00542963]\n",
      "Iteration: 40 Loss -2.88 Acc: [0.99509937 0.00490069]\n",
      "Iteration: 41 Loss -2.91 Acc: [0.9947619 0.0052381]\n",
      "Iteration: 42 Loss -2.89 Acc: [0.995678   0.00432197]\n",
      "Iteration: 43 Loss -3.03 Acc: [0.99604636 0.00395363]\n",
      "Iteration: 44 Loss -2.96 Acc: [0.9959991  0.00400092]\n",
      "Iteration: 45 Loss -3.11 Acc: [0.99669915 0.00330078]\n",
      "Iteration: 46 Loss -3.12 Acc: [0.9965969  0.00340318]\n",
      "Iteration: 47 Loss -3.20 Acc: [0.997083   0.00291698]\n",
      "Iteration: 48 Loss -3.25 Acc: [0.99733573 0.00266419]\n",
      "Iteration: 49 Loss -3.28 Acc: [0.9973615  0.00263848]\n",
      "Iteration: 50 Loss -3.20 Acc: [0.9973375  0.00266251]\n",
      "Iteration: 51 Loss -3.18 Acc: [0.9967602  0.00323981]\n",
      "Iteration: 52 Loss -3.25 Acc: [0.99761546 0.00238453]\n",
      "Iteration: 53 Loss -3.25 Acc: [0.99701107 0.00298887]\n",
      "Iteration: 54 Loss -3.39 Acc: [0.9981494  0.00185064]\n",
      "Iteration: 55 Loss -3.46 Acc: [0.9980715  0.00192856]\n",
      "Iteration: 56 Loss -3.46 Acc: [0.99831617 0.00168385]\n",
      "Iteration: 57 Loss -3.58 Acc: [0.99851686 0.00148318]\n",
      "Iteration: 58 Loss -3.64 Acc: [0.9987081  0.00129185]\n",
      "Iteration: 59 Loss -3.62 Acc: [0.99861526 0.00138475]\n",
      "Iteration: 60 Loss -3.66 Acc: [0.9987627  0.00123729]\n",
      "Iteration: 61 Loss -3.57 Acc: [0.9983551  0.00164494]\n",
      "Iteration: 62 Loss -3.64 Acc: [0.9987686  0.00123137]\n",
      "Iteration: 63 Loss -3.75 Acc: [0.9988392  0.00116083]\n",
      "Iteration: 64 Loss -3.83 Acc: [9.9910080e-01 8.9923263e-04]\n",
      "Iteration: 65 Loss -3.90 Acc: [9.991233e-01 8.766877e-04]\n",
      "Iteration: 66 Loss -3.95 Acc: [9.992855e-01 7.144493e-04]\n",
      "Iteration: 67 Loss -3.96 Acc: [9.991393e-01 8.606332e-04]\n",
      "Iteration: 68 Loss -3.99 Acc: [9.9933618e-01 6.6374533e-04]\n",
      "Iteration: 69 Loss -4.06 Acc: [9.9929070e-01 7.0926506e-04]\n",
      "Iteration: 70 Loss -4.08 Acc: [9.9943513e-01 5.6480337e-04]\n",
      "Iteration: 71 Loss -4.17 Acc: [9.994665e-01 5.335214e-04]\n",
      "Iteration: 72 Loss -4.13 Acc: [9.9948466e-01 5.1533984e-04]\n",
      "Iteration: 73 Loss -4.19 Acc: [9.9946564e-01 5.3441187e-04]\n",
      "Iteration: 74 Loss -4.14 Acc: [9.9954921e-01 4.5078632e-04]\n",
      "Iteration: 75 Loss -4.08 Acc: [9.993111e-01 6.888955e-04]\n",
      "Iteration: 76 Loss -4.48 Acc: [9.9971455e-01 2.8546975e-04]\n",
      "Iteration: 77 Loss -4.47 Acc: [9.996730e-01 3.269896e-04]\n",
      "Iteration: 78 Loss -4.40 Acc: [9.9970466e-01 2.9536066e-04]\n",
      "Iteration: 79 Loss -4.46 Acc: [9.9968731e-01 3.1268172e-04]\n",
      "Iteration: 80 Loss -4.65 Acc: [9.9981004e-01 1.8992972e-04]\n",
      "Iteration: 81 Loss -4.82 Acc: [9.9984801e-01 1.5195535e-04]\n",
      "Iteration: 82 Loss -4.86 Acc: [9.998667e-01 1.332062e-04]\n",
      "Iteration: 83 Loss -4.91 Acc: [9.9985003e-01 1.4994216e-04]\n",
      "Iteration: 84 Loss -4.88 Acc: [9.9987781e-01 1.2216387e-04]\n",
      "Iteration: 85 Loss -5.10 Acc: [9.9991584e-01 8.4126856e-05]\n",
      "Iteration: 86 Loss -5.16 Acc: [9.9991345e-01 8.6498818e-05]\n",
      "Iteration: 87 Loss -5.28 Acc: [9.9993706e-01 6.2982166e-05]\n",
      "Iteration: 88 Loss -5.24 Acc: [9.999199e-01 8.015157e-05]\n",
      "Iteration: 89 Loss -5.31 Acc: [9.9994302e-01 5.6962966e-05]\n",
      "Iteration: 90 Loss -5.44 Acc: [9.9995363e-01 4.6415844e-05]\n",
      "Iteration: 91 Loss -5.50 Acc: [9.9995482e-01 4.5132907e-05]\n",
      "Iteration: 92 Loss -5.52 Acc: [9.9996209e-01 3.7851005e-05]\n",
      "Iteration: 93 Loss -5.89 Acc: [9.9998033e-01 1.9652805e-05]\n",
      "Iteration: 94 Loss -5.93 Acc: [9.9998295e-01 1.7004142e-05]\n",
      "Iteration: 95 Loss -5.95 Acc: [9.9997997e-01 1.9983543e-05]\n",
      "Iteration: 96 Loss -5.99 Acc: [9.9998450e-01 1.5540592e-05]\n",
      "Iteration: 97 Loss -6.29 Acc: [9.9999094e-01 9.0237918e-06]\n",
      "Iteration: 98 Loss -6.40 Acc: [9.999924e-01 7.627281e-06]\n",
      "Iteration: 99 Loss -6.15 Acc: [9.999901e-01 9.881282e-06]\n",
      "Iteration: 1 Loss -0.25 Acc: [0.37785983 0.62214017]\n",
      "Iteration: 2 Loss -0.74 Acc: [0.13820326 0.86179674]\n",
      "Iteration: 3 Loss -1.00 Acc: [0.07877139 0.9212286 ]\n",
      "Iteration: 4 Loss -1.22 Acc: [0.05483311 0.94516695]\n",
      "Iteration: 5 Loss -1.44 Acc: [0.03431217 0.9656879 ]\n",
      "Iteration: 6 Loss -1.73 Acc: [0.02713754 0.9728625 ]\n",
      "Iteration: 7 Loss -2.04 Acc: [0.01497392 0.98502606]\n",
      "Iteration: 8 Loss -2.40 Acc: [0.00799654 0.9920034 ]\n",
      "Iteration: 9 Loss -2.72 Acc: [0.00442136 0.9955786 ]\n",
      "Iteration: 10 Loss -3.05 Acc: [0.00235872 0.9976413 ]\n",
      "Iteration: 11 Loss -3.42 Acc: [0.00122135 0.99877864]\n",
      "Iteration: 12 Loss -3.98 Acc: [4.2699333e-04 9.9957305e-01]\n",
      "Iteration: 13 Loss -4.64 Acc: [1.2126787e-04 9.9987876e-01]\n",
      "Iteration: 14 Loss -5.39 Acc: [2.7089136e-05 9.9997294e-01]\n",
      "Iteration: 15 Loss -6.37 Acc: [3.585365e-06 9.999964e-01]\n",
      "Iteration: 16 Loss -7.26 Acc: [6.398829e-07 9.999994e-01]\n",
      "Iteration: 17 Loss -8.25 Acc: [9.3422415e-08 9.9999988e-01]\n",
      "Iteration: 18 Loss -9.45 Acc: [8.2248635e-09 1.0000000e+00]\n",
      "Iteration: 19 Loss -11.34 Acc: [2.6091515e-10 1.0000000e+00]\n",
      "Iteration: 20 Loss -13.76 Acc: [2.6202252e-12 1.0000000e+00]\n",
      "Iteration: 21 Loss -16.68 Acc: [1.1252662e-14 1.0000000e+00]\n",
      "Iteration: 22 Loss -20.00 Acc: [2.2417518e-17 1.0000000e+00]\n",
      "Iteration: 23 Loss -23.53 Acc: [3.1647623e-20 1.0000000e+00]\n",
      "Iteration: 24 Loss -27.17 Acc: [3.513962e-23 1.000000e+00]\n",
      "Iteration: 25 Loss -31.35 Acc: [1.601917e-26 1.000000e+00]\n",
      "Iteration: 26 Loss -35.75 Acc: [4.8200505e-30 1.0000000e+00]\n",
      "Iteration: 27 Loss -40.13 Acc: [1.3064996e-33 1.0000000e+00]\n",
      "Iteration: 28 Loss -44.36 Acc: [4.5737113e-37 1.0000000e+00]\n",
      "Iteration: 29 Loss -48.95 Acc: [9.5473e-41 1.0000e+00]\n",
      "Iteration: 30 Loss -52.45 Acc: [1.18e-43 1.00e+00]\n",
      "Iteration: 31 Loss -56.29 Acc: [0. 1.]\n",
      "Iteration: 32 Loss -59.85 Acc: [0. 1.]\n",
      "Iteration: 33 Loss -62.95 Acc: [0. 1.]\n",
      "Iteration: 34 Loss -66.14 Acc: [0. 1.]\n",
      "Iteration: 35 Loss -68.45 Acc: [0. 1.]\n",
      "Iteration: 36 Loss -71.17 Acc: [0. 1.]\n",
      "Iteration: 37 Loss -73.82 Acc: [0. 1.]\n",
      "Iteration: 38 Loss -76.40 Acc: [0. 1.]\n",
      "Iteration: 39 Loss -77.90 Acc: [0. 1.]\n",
      "Iteration: 40 Loss -80.37 Acc: [0. 1.]\n",
      "Iteration: 41 Loss -81.96 Acc: [0. 1.]\n",
      "Iteration: 42 Loss -83.50 Acc: [0. 1.]\n",
      "Iteration: 43 Loss -85.40 Acc: [0. 1.]\n",
      "Iteration: 44 Loss -87.15 Acc: [0. 1.]\n",
      "Iteration: 45 Loss -89.22 Acc: [0. 1.]\n",
      "Iteration: 46 Loss -90.81 Acc: [0. 1.]\n",
      "Iteration: 47 Loss -91.74 Acc: [0. 1.]\n",
      "Iteration: 48 Loss -92.99 Acc: [0. 1.]\n",
      "Iteration: 49 Loss -94.75 Acc: [0. 1.]\n",
      "Iteration: 50 Loss -96.31 Acc: [0. 1.]\n",
      "Iteration: 51 Loss -97.20 Acc: [0. 1.]\n",
      "Iteration: 52 Loss -98.72 Acc: [0. 1.]\n",
      "Iteration: 53 Loss -99.05 Acc: [0. 1.]\n",
      "Iteration: 54 Loss -100.70 Acc: [0. 1.]\n",
      "Iteration: 55 Loss -100.08 Acc: [0. 1.]\n",
      "Iteration: 56 Loss -103.13 Acc: [0. 1.]\n",
      "Iteration: 57 Loss -103.53 Acc: [0. 1.]\n",
      "Iteration: 58 Loss -105.76 Acc: [0. 1.]\n",
      "Iteration: 59 Loss -105.96 Acc: [0. 1.]\n",
      "Iteration: 60 Loss -108.27 Acc: [0. 1.]\n",
      "Iteration: 61 Loss -109.35 Acc: [0. 1.]\n",
      "Iteration: 62 Loss -111.16 Acc: [0. 1.]\n",
      "Iteration: 63 Loss -112.63 Acc: [0. 1.]\n",
      "Iteration: 64 Loss -114.09 Acc: [0. 1.]\n",
      "Iteration: 65 Loss -114.75 Acc: [0. 1.]\n",
      "Iteration: 66 Loss -117.42 Acc: [0. 1.]\n",
      "Iteration: 67 Loss -118.78 Acc: [0. 1.]\n",
      "Iteration: 68 Loss -120.37 Acc: [0. 1.]\n",
      "Iteration: 69 Loss -120.89 Acc: [0. 1.]\n",
      "Iteration: 70 Loss -122.47 Acc: [0. 1.]\n",
      "Iteration: 71 Loss -124.88 Acc: [0. 1.]\n",
      "Iteration: 72 Loss -125.80 Acc: [0. 1.]\n",
      "Iteration: 73 Loss -127.57 Acc: [0. 1.]\n",
      "Iteration: 74 Loss -128.79 Acc: [0. 1.]\n",
      "Iteration: 75 Loss -131.22 Acc: [0. 1.]\n",
      "Iteration: 76 Loss -132.10 Acc: [0. 1.]\n",
      "Iteration: 77 Loss -133.47 Acc: [0. 1.]\n",
      "Iteration: 78 Loss -134.58 Acc: [0. 1.]\n",
      "Iteration: 79 Loss -136.29 Acc: [0. 1.]\n",
      "Iteration: 80 Loss -137.55 Acc: [0. 1.]\n",
      "Iteration: 81 Loss -140.13 Acc: [0. 1.]\n",
      "Iteration: 82 Loss -141.34 Acc: [0. 1.]\n",
      "Iteration: 83 Loss -142.57 Acc: [0. 1.]\n",
      "Iteration: 84 Loss -142.52 Acc: [0. 1.]\n",
      "Iteration: 85 Loss -145.18 Acc: [0. 1.]\n",
      "Iteration: 86 Loss -145.78 Acc: [0. 1.]\n",
      "Iteration: 87 Loss -147.12 Acc: [0. 1.]\n",
      "Iteration: 88 Loss -148.96 Acc: [0. 1.]\n",
      "Iteration: 89 Loss -151.37 Acc: [0. 1.]\n",
      "Iteration: 90 Loss -151.78 Acc: [0. 1.]\n",
      "Iteration: 91 Loss -155.12 Acc: [0. 1.]\n",
      "Iteration: 92 Loss -156.10 Acc: [0. 1.]\n",
      "Iteration: 93 Loss -156.97 Acc: [0. 1.]\n",
      "Iteration: 94 Loss -161.11 Acc: [0. 1.]\n",
      "Iteration: 95 Loss -164.64 Acc: [0. 1.]\n",
      "Iteration: 96 Loss -166.75 Acc: [0. 1.]\n",
      "Iteration: 97 Loss -168.97 Acc: [0. 1.]\n",
      "Iteration: 98 Loss -171.51 Acc: [0. 1.]\n",
      "Iteration: 99 Loss -173.92 Acc: [0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 0\n",
    "lr = 0.1\n",
    "range_Images = 100\n",
    "rand_loc = 'input_noise_OU200.npy'\n",
    "for j in range(2):\n",
    "                target_class = j \n",
    "                model = OU200_CNN()\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "                model.load_state_dict(torch.load(loadStates['OU-200'],map_location=torch.device('cpu')))\n",
    "\n",
    "                input_img = np.load(rand_loc)\n",
    "\n",
    "\n",
    "                if target_class == 0:\n",
    "                        file_loc = 'Non_Lens_Gifs/non_lenses'\n",
    "                else:\n",
    "                        file_loc = 'Lens_Gifs/Lenses'\n",
    " \n",
    "                loc = 'generated/OU200/'+str(range_Images)+'/'+file_loc+'_'+str(lr)+'_No_'+str(k)+'C_SameRandom4AllBands/'\n",
    "                if not os.path.exists(loc):\n",
    "                    os.makedirs(loc)\n",
    "                  \n",
    "                pretrained_model = model\n",
    "                csig = ClassSpecificImageGeneration(pretrained_model, target_class, lr, loc, input_img, range_Images)\n",
    "                csig.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Class Activating Images for each Conv2D layer \n",
    "\n",
    "This works on the same principle as Class Generated Images. However instead of focusing on the output layer, we focus on the Conv2D layers and all the filters within these layers. These layers are at different locations for the different architectures used within this work. \n",
    "\n",
    "This process creates images that are the same dimensions as the inputs to OU-200 that highly activate a specific layer and filter. This can indicate what each filter in the Conv2D layers is detecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OU66_CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model.load_state_dict(torch.load(loadStates['OU-66'],map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,4,7,10,13,17,20,23,26]:\n",
    "    for j in range(model.layer[i].weight.data.shape[0]):\n",
    "        cnn_layer = i\n",
    "        filter_pos = j\n",
    "        lr = 0.1\n",
    "        steps = 50\n",
    "    # Fully connected layer is not needed\n",
    "        pretrained_model = model\n",
    "        input_Size = [4,200,200]\n",
    "        path = 'generated/OU66_Filters_Run1'\n",
    "        if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "    #pretrained_model = models.vgg16(pretrained=True).features\n",
    "    \n",
    "        layer_vis = CNNLayerVisualization(pretrained_model, cnn_layer, filter_pos, lr, steps,path,input_Size)\n",
    "\n",
    "    # Layer visualization with pytorch hooks\n",
    "        layer_vis.visualise_layer_with_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OU200_CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model.load_state_dict(torch.load(loadStates['OU-200'],map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,4,8,12,16,19]:\n",
    "    for j in range(model.layer[i].weight.data.shape[0]):\n",
    "        cnn_layer = i\n",
    "        filter_pos = j\n",
    "        lr = 0.1\n",
    "        steps = 50\n",
    "    # Fully connected layer is not needed\n",
    "        pretrained_model = model\n",
    "        input_Size = [4,200,200]\n",
    "        path = 'generated/OU200_Filters_Run1'\n",
    "        if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "    #pretrained_model = models.vgg16(pretrained=True).features\n",
    "        layer_vis = CNNLayerVisualization(pretrained_model, cnn_layer, filter_pos, lr, steps,path,input_Size)\n",
    "\n",
    "    # Layer visualization with pytorch hooks\n",
    "        layer_vis.visualise_layer_with_hooks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
